{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45f5948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5676af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(txt:str):\n",
    "    txt = re.sub('[^a-zA-Z]', ' ', txt) \n",
    "    txt = txt.lower()\n",
    "    txt = \" \".join(txt.split()) \n",
    "    \n",
    "    doc = nlp(txt)\n",
    "    \n",
    "    tokens_filtered = []\n",
    "    # Iterate through tokens and append to list if its not stop word or punctuation mark\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        tokens_filtered.append(token.lemma_)\n",
    "        \n",
    "    return \" \".join(tokens_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d1ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "\n",
    "df = pd.read_csv('df_file.csv')\n",
    "df['Text'] = df['Text'].apply(lambda x:x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2835b903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>prep_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election  Gordon Brown...</td>\n",
       "      <td>0</td>\n",
       "      <td>budget set scene election gordon brown seek ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision  Military ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>army chief regiment decision military chief ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards  Michael How...</td>\n",
       "      <td>0</td>\n",
       "      <td>howard deny split d card michael howard deny s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election  Ministers wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>observer monitor uk election minister invite i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target  Ex-chat sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>kilroy name election seat target ex chat host ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  Budget to set scene for election  Gordon Brown...      0   \n",
       "1  Army chiefs in regiments decision  Military ch...      0   \n",
       "2  Howard denies split over ID cards  Michael How...      0   \n",
       "3  Observers to monitor UK election  Ministers wi...      0   \n",
       "4  Kilroy names election seat target  Ex-chat sho...      0   \n",
       "\n",
       "                                           prep_text  \n",
       "0  budget set scene election gordon brown seek ec...  \n",
       "1  army chief regiment decision military chief ex...  \n",
       "2  howard deny split d card michael howard deny s...  \n",
       "3  observer monitor uk election minister invite i...  \n",
       "4  kilroy name election seat target ex chat host ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df.drop_duplicates(ignore_index = True, inplace=True)\n",
    "\n",
    "# Preprocess text\n",
    "df['prep_text'] = df['Text'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f809fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows used in training: 1701\n",
      "Rows used in evaluation: 426\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5,ngram_range=(1, 2), stop_words='english')\n",
    "features = vectorizer.fit_transform(df['prep_text']).toarray()\n",
    "\n",
    "X = features\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "print(f'Rows used in training: {len(X_train)}')\n",
    "print(f'Rows used in evaluation: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c3769ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99120235 0.98823529 0.96176471 0.97352941 0.97058824]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_alg = {'model':LogisticRegression()}\n",
    "scores = {}\n",
    "\n",
    "try:\n",
    "    model = training_alg['model'].fit(X_train, y_train, \n",
    "        early_stopping_rounds=10,\n",
    "        eval_metric='merror',\n",
    "        eval_set=[(X_test, y_test)])\n",
    "    \n",
    "except TypeError:\n",
    "    classifiers['model'].fit(X_train, y_train)\n",
    "    \n",
    "training_score = cross_val_score(training_alg['model'], X_train, y_train, cv=5, scoring='accuracy') \n",
    "avg_score = round(np.mean(training_score) * 100, 2)\n",
    "\n",
    "joblib.dump(training_alg[\"model\"], \"model.joblib\")\n",
    "\n",
    "print(training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5102cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cb726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
